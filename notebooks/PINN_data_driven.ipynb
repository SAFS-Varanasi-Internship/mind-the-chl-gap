{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import deepxde as dde\n",
    "import os\n",
    "os.environ[\"DDEBACKEND\"] = \"pytorch\"\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.gap_data_utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_preprocess_data():\n",
    "    # Load and preprocess the data\n",
    "    zarr_path = \"~/shared-public/mind_the_chl_gap/U-Net_with_CHL_pred.zarr\"\n",
    "    zarr_ds = xr.open_zarr(zarr_path)[\"gapfree_pred\"]\n",
    "\n",
    "    # Load gappy data (level 3)\n",
    "    level3_path = \"~/shared-public/mind_the_chl_gap/IO.zarr\"\n",
    "    level3_ds = xr.open_zarr(level3_path).sel(\n",
    "        lat=slice(zarr_ds.lat.values.max(), zarr_ds.lat.values.min()),\n",
    "        lon=slice(zarr_ds.lon.values.min(), zarr_ds.lon.values.max()),\n",
    "    )\n",
    "    # Extract latitude and longitude extents to determine height and width\n",
    "    lat = level3_ds.lat.values\n",
    "    lon = level3_ds.lon.values\n",
    "\n",
    "    # Set a time slice for the datasets\n",
    "    time_slice = slice(\"2022-01-01\", \"2022-12-31\")  # Adjust as needed\n",
    "    gappy_data = level3_ds.sel(time=time_slice)\n",
    "\n",
    "    return gappy_data, lat, lon\n",
    "\n",
    "\n",
    "def stack_data(gappy_data, flatten=True):\n",
    "    # Variables to include in the branch net\n",
    "    variables = [\"CHL_cmes-level3\", \"sst\", \"u_wind\", \"v_wind\", \"air_temp\", \"ug_curr\"]\n",
    "\n",
    "    # Prepare the data by stacking variables for each time slice\n",
    "    stacked_data = np.stack([gappy_data[var].values for var in variables], axis=1)\n",
    "    stacked_data = np.transpose(\n",
    "        stacked_data, (0, 2, 3, 1)\n",
    "    )  # Shape: (train_size, height, width, num_variables)\n",
    "    if flatten:\n",
    "        timesteps, w, h, channels = stacked_data.shape\n",
    "        stacked_data = stacked_data.reshape(timesteps, w * h, channels)\n",
    "    return stacked_data\n",
    "\n",
    "\n",
    "def get_random_coords(gappy_data, n_samples):\n",
    "    m = gappy_data.shape[0]\n",
    "    coord_array = np.empty((m, n_samples), dtype=float)\n",
    "    for t_idx in range(m):\n",
    "        chl_data = gappy_data[t_idx, :, 0]\n",
    "        valid_coords = np.argwhere(~np.isnan(chl_data))\n",
    "        if len(valid_coords) > 0:\n",
    "            selected_coords = valid_coords[\n",
    "                np.random.choice(len(valid_coords), n_samples, replace=False)\n",
    "            ]\n",
    "            coord_array[t_idx] = selected_coords.flatten()\n",
    "    return coord_array.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gappy_data, lat, lon = load_preprocess_data()\n",
    "stacked_data = stack_data(gappy_data)\n",
    "train_ims, test_ims = split_train_test(stacked_data, frac_train=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds = get_random_coords(train_ims, 100)\n",
    "test_inds = get_random_coords(test_ims, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((292, 42240, 6), (73, 42240, 6))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ims.shape, test_ims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(data, inds):\n",
    "    if len(data.shape) > 3:\n",
    "        timesteps, w, h, channels = data.shape\n",
    "        data = data.reshape(timesteps, w * h, channels)\n",
    "    result = data[np.arange(data.shape[0])[:, None], inds, :]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = sample_data(train_ims, train_inds)[:, :, 0]\n",
    "y_test = sample_data(test_ims, test_inds)[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.nan_to_num(train_ims.reshape(train_ims.shape[0], -1), nan=0.0)\n",
    "x_test = np.nan_to_num(test_ims.reshape(test_ims.shape[0], -1), nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (292, 253440), y_train shape: (292, 100), train_inds shape: (292, 100)\n",
      "x_test shape: (73, 253440), y_test shape: (73, 100), test_inds shape: (73, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}, train_inds shape: {train_inds.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}, test_inds shape: {test_inds.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.000150 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric   \n",
      "0         [1.28e+15]    [1.42e+15]    [7.94e+07]    \n",
      "1000      [8.78e+12]    [1.47e+12]    [2.04e+06]    \n"
     ]
    }
   ],
   "source": [
    "# DeepONet setup\n",
    "m = x_train.shape[1]  # 253440\n",
    "dim_x = train_inds.shape[1]  # index/sensor dimension\n",
    "\n",
    "net = dde.nn.DeepONet(\n",
    "    [m, 512, 512, 40],  # Branch net architecture\n",
    "    [dim_x, 40, 40],  # Trunk net architecture\n",
    "    \"relu\",\n",
    "    \"Glorot normal\",\n",
    ")\n",
    "\n",
    "data = dde.data.Triple(\n",
    "    X_train=(x_train, train_inds.astype(np.float32)),\n",
    "    y_train=y_train,\n",
    "    X_test=(x_test, test_inds.astype(np.float32)),\n",
    "    y_test=y_test,\n",
    ")\n",
    "\n",
    "model = dde.Model(data, net)\n",
    "model.compile(\"adam\", lr=0.001, metrics=[\"mean l2 relative error\"])\n",
    "losshistory, train_state = model.train(iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
